from __future__ import absolute_import
from __future__ import print_function
from __future__ import division

import tensorflow as tf
import numpy as np

import time
import discogan

import sys
sys.path.insert(0, '../')

from datasets import DataSet
import image_utils as iu


dirs = {
    'sample_output': './DiscoGAN/',
    'checkpoint': './model/checkpoint',
    'model': './model/DiscoGAN-model.ckpt'
}
paras = {
    'epoch': 250,
    'batch_size': 256,
    'logging_interval': 1000
}


def main():
    start_time = time.time()  # clocking start

    # Dataset
    dataset = DataSet(dataset_name="pix2pix_vangogh")

    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    with tf.Session(config=config) as s:
        # DiscoGAN model
        model = discogan.DiscoGAN(s, batch_A=dataset.batch_A, batch_B=dataset.batch_B)

        # load model & graph & weight
        ckpt = tf.train.get_checkpoint_state('./model/')
        if ckpt and ckpt.model_checkpoint_path:
            # Restores from checkpoint
            model.saver.restore(s, ckpt.model_checkpoint_path)

            step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
            print("[+] global step : %s" % step, " successfully loaded")
        else:
            step = 0
            print('[-] No checkpoint file found')

        # initializing variables
        tf.global_variables_initializer().run()

        d_overpowered = False  # G loss > D loss * 2
        for epoch in range(paras['epoch']):
            # update D network
            if not d_overpowered:
                s.run(model.d_op)

            # update G network
            s.run(model.g_op)

            if step % paras['logging_interval'] == 0:
                d_loss, g_loss, summary = s.run([
                    model.d_loss,
                    model.g_loss,
                    model.merged
                ])

                # print loss
                print("[+] Epoch %03d Step %05d => " % (epoch, step),
                      "D loss : {:.8f}".format(d_loss), " G loss : {:.8f}".format(g_loss))

                # update overpowered
                d_overpowered = d_loss < g_loss / 2

                # training G model with sample image and noise
                s2b_samples = s.run(model.G_s2b)
                b2s_samples = s.run(model.G_b2s)

                # summary saver
                model.writer.add_summary(summary, step)

                # export image generated by model G
                sample_image_height = model.sample_size
                sample_image_width = model.sample_size
                sample_s2b_dir = dirs['sample_output'] + 'train_A_{0}_{1}.png'.format(epoch, step)
                sample_b2s_dir = dirs['sample_output'] + 'train_B_{0}_{1}.png'.format(epoch, step)

                # Generated image save
                iu.save_images(s2b_samples, size=[sample_image_height, sample_image_width],
                               image_path=sample_s2b_dir)
                iu.save_images(b2s_samples, size=[sample_image_height, sample_image_width],
                               image_path=sample_b2s_dir)

                # model save
                model.saver.save(s, dirs['model'], global_step=step)

            step += 1

        end_time = time.time() - start_time

        # elapsed time
        print("[+] Elapsed time {:.8f}s".format(end_time))

        # close tf.Session
        s.close()

if __name__ == '__main__':
    main()
